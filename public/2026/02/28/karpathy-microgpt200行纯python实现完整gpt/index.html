<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.148.1">
  <meta name="google-site-verification" content="cjUeAB94_LgGaOQ3rk5sUy6wCk-o8N85tKvKJ98-ifM" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="" />
  <meta property="og:url" content="https://muzig.io/2026/02/28/karpathy-microgpt200%E8%A1%8C%E7%BA%AFpython%E5%AE%9E%E7%8E%B0%E5%AE%8C%E6%95%B4gpt/" />
  <link rel="canonical" href="https://muzig.io/2026/02/28/karpathy-microgpt200%E8%A1%8C%E7%BA%AFpython%E5%AE%9E%E7%8E%B0%E5%AE%8C%E6%95%B4gpt/" /><link
    rel="alternate"
    type="application/atom+xml"
    href="https://muzig.io/index.xml"
    title="Muzig çš„æŠ€æœ¯åšå®¢"
  />

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/muzig.io\/"
      },
      "articleSection" : "posts",
      "name" : "Karpathy microGPTï¼š200è¡Œçº¯Pythonå®ç°å®Œæ•´GPT",
      "headline" : "Karpathy microGPTï¼š200è¡Œçº¯Pythonå®ç°å®Œæ•´GPT",
      "description" : " \u0026ldquo;The most atomic way to train and run inference for a GPT in pure, dependency-free Python. This file is the complete algorithm. Everything else is just efficiency.\u0026rdquo; â€” Andrej Karpathy\næœ€è¿‘ Andrej Karpathy å‘å¸ƒäº†ä¸€ä¸ªæç®€ GPT å®ç°ï¼šmicrogpt.py â€”â€” ä»… 200 è¡Œçº¯ Python ä»£ç ï¼Œæ— ä»»ä½•å¤–éƒ¨ä¾èµ–ï¼ˆåªç”¨æ ‡å‡†åº“ os, math, randomï¼‰ï¼Œå´åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒã€æ¨ç†æµç¨‹ã€‚\nè¿™ä¸æ˜¯ç©å…·ä»£ç ï¼Œè€Œæ˜¯ä¸€ä¸ªæ•™å­¦æ°ä½œï¼šå®ƒå‰¥ç¦»äº†æ‰€æœ‰å·¥ç¨‹å¤æ‚æ€§ï¼Œè®©ä½ çœ‹åˆ° GPT çš„ç®—æ³•æœ¬è´¨ã€‚\n",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2026",
      "datePublished": "2026-02-28 21:30:00 \u002b0800 CST",
      "dateModified" : "2026-02-28 21:30:00 \u002b0800 CST",
      "url" : "https:\/\/muzig.io\/2026\/02\/28\/karpathy-microgpt200%E8%A1%8C%E7%BA%AFpython%E5%AE%9E%E7%8E%B0%E5%AE%8C%E6%95%B4gpt\/",
      "keywords" : [ "LLM","GPT","Transformer","Python","Education","Karpathy", ]
  }
</script>
<title>Karpathy microGPTï¼š200è¡Œçº¯Pythonå®ç°å®Œæ•´GPT</title>
  <meta property="og:title" content="Karpathy microGPTï¼š200è¡Œçº¯Pythonå®ç°å®Œæ•´GPT" />
  <meta property="og:type" content="article" />
  <meta
    property="og:description"
    content=" &ldquo;The most atomic way to train and run inference for a GPT in pure, dependency-free Python. This file is the complete algorithm. Everything else is just efficiency.&rdquo; â€” Andrej Karpathy
æœ€è¿‘ Andrej Karpathy å‘å¸ƒäº†ä¸€ä¸ªæç®€ GPT å®ç°ï¼šmicrogpt.py â€”â€” ä»… 200 è¡Œçº¯ Python ä»£ç ï¼Œæ— ä»»ä½•å¤–éƒ¨ä¾èµ–ï¼ˆåªç”¨æ ‡å‡†åº“ os, math, randomï¼‰ï¼Œå´åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒã€æ¨ç†æµç¨‹ã€‚
è¿™ä¸æ˜¯ç©å…·ä»£ç ï¼Œè€Œæ˜¯ä¸€ä¸ªæ•™å­¦æ°ä½œï¼šå®ƒå‰¥ç¦»äº†æ‰€æœ‰å·¥ç¨‹å¤æ‚æ€§ï¼Œè®©ä½ çœ‹åˆ° GPT çš„ç®—æ³•æœ¬è´¨ã€‚
"
  />
  <meta
    name="description"
    content=" &ldquo;The most atomic way to train and run inference for a GPT in pure, dependency-free Python. This file is the complete algorithm. Everything else is just efficiency.&rdquo; â€” Andrej Karpathy
æœ€è¿‘ Andrej Karpathy å‘å¸ƒäº†ä¸€ä¸ªæç®€ GPT å®ç°ï¼šmicrogpt.py â€”â€” ä»… 200 è¡Œçº¯ Python ä»£ç ï¼Œæ— ä»»ä½•å¤–éƒ¨ä¾èµ–ï¼ˆåªç”¨æ ‡å‡†åº“ os, math, randomï¼‰ï¼Œå´åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒã€æ¨ç†æµç¨‹ã€‚
è¿™ä¸æ˜¯ç©å…·ä»£ç ï¼Œè€Œæ˜¯ä¸€ä¸ªæ•™å­¦æ°ä½œï¼šå®ƒå‰¥ç¦»äº†æ‰€æœ‰å·¥ç¨‹å¤æ‚æ€§ï¼Œè®©ä½ çœ‹åˆ° GPT çš„ç®—æ³•æœ¬è´¨ã€‚
"
  />
  <meta property="og:locale" content="zh-cn" /><meta property="og:image" content="" />
  
  
  <style>:root{--bg-color:#ffffff;--text-color:#000000;--link-color:#000000;--border-color:#482936;--secondary-text:#666666;--code-bg:#f6f8fa;--blockquote-color:#57606a;--blockquote-border:#d0d7de;--disqus-bg:white}[data-theme=dark]{--bg-color:#1a1a1a;--text-color:#e0e0e0;--link-color:#b0b0b0;--border-color:#8b5a7a;--secondary-text:#aaaaaa;--code-bg:#2d2d2d;--blockquote-color:#a0a0a0;--blockquote-border:#404040;--disqus-bg:#1a1a1a}body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px;background-color:var(--bg-color);color:var(--text-color)}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:var(--link-color);text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:var(--link-color)}.markdown-body blockquote{margin:0;padding:0 1em;color:var(--blockquote-color);border-left:.25em solid var(--blockquote-border)}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px;background-color:var(--code-bg)}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:var(--code-bg);border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:var(--code-bg);border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:var(--secondary-text)}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-item-left{margin-left:5px;margin-right:auto}.header-line{width:100%;border-width:2px;border-color:var(--border-color);border-style:solid none none none}.lang-switch{font-weight:600}.theme-toggle{background:0 0;border:none;color:var(--link-color);cursor:pointer;font-weight:600;font-size:inherit;padding:0}.theme-toggle:hover{font-weight:800}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:var(--text-color)2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:var(--text-color)2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:6px}.post-content .post-gallery{display:flex;flex-wrap:wrap;gap:6px}.post-content .post-gallery img{margin-right:auto;margin-top:auto;width:calc(50% - 3px)}.related-content{border-width:3px;border-style:solid;border-color:var(--text-color);padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:var(--disqus-bg)}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}.post-content .post-gallery img{width:100%}}@media screen and (max-width:48em){.posts-category{display:none}}</style>
  
  
  <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  
   <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Muzig çš„æŠ€æœ¯åšå®¢">
  
  <link rel="preconnect" href="https://fonts.gstatic.com" />
  <link
    href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade"
    rel="stylesheet"
  />
  
  

  
  <script data-cfasync="false">
    (function() {
      const themeKey = 'theme';
      const themes = { light: 'light', dark: 'dark', system: 'system' };

      function getSystemTheme() {
        return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
      }
      function getStoredTheme() {
        return localStorage.getItem(themeKey);
      }
      function getCurrentTheme() {
        const stored = getStoredTheme();
        if (stored && stored !== themes.system) {
          return stored;
        }
        return getSystemTheme();
      }
      function setTheme(theme) {
        const root = document.documentElement;
        if (theme === themes.system) {
          theme = getSystemTheme();
        }
        if (theme === themes.dark) {
          root.setAttribute('data-theme', 'dark');
        } else {
          root.removeAttribute('data-theme');
        }
        updateToggleButton(theme);
      }
      function updateToggleButton(theme) {
        const button = document.getElementById('theme-toggle');
        if (button) {
          button.textContent = theme === 'dark' ? 'â˜€ï¸' : 'ğŸŒ™';
        }
      }
      function ensureButtonUpdated() {
        updateToggleButton(getCurrentTheme());
      }
      function initTheme() {
        const stored = getStoredTheme();
        let theme;
        if (stored) {
          theme = stored === themes.system ? getSystemTheme() : stored;
          setTheme(stored);
        } else {
          
          theme = getSystemTheme();
          setTheme(themes.system);
        }
      }
      function toggleTheme() { 
        const current = getStoredTheme() || themes.system;
        let next;
        if (current === themes.system) {
          next = getSystemTheme() === 'dark' ? themes.light : themes.dark;
        } else if (current === themes.dark) {
          next = themes.light;
        } else {
          next = themes.dark;
        }
        localStorage.setItem(themeKey, next);
        setTheme(next);
      }

      
      window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', function(e) {
        const stored = getStoredTheme();
        if (!stored || stored === themes.system) {
          setTheme(themes.system);
        }
      });

      
      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', ensureButtonUpdated);
      } else {
        
        ensureButtonUpdated();
      }

      
      window.toggleTheme = toggleTheme;

      
      initTheme();
    })();
  </script>
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Karpathy microGPTï¼š200è¡Œçº¯Pythonå®ç°å®Œæ•´GPT">
  <meta name="twitter:description" content="â€œThe most atomic way to train and run inference for a GPT in pure, dependency-free Python. This file is the complete algorithm. Everything else is just efficiency.â€ â€” Andrej Karpathy
æœ€è¿‘ Andrej Karpathy å‘å¸ƒäº†ä¸€ä¸ªæç®€ GPT å®ç°ï¼šmicrogpt.py â€”â€” ä»… 200 è¡Œçº¯ Python ä»£ç ï¼Œæ— ä»»ä½•å¤–éƒ¨ä¾èµ–ï¼ˆåªç”¨æ ‡å‡†åº“ os, math, randomï¼‰ï¼Œå´åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒã€æ¨ç†æµç¨‹ã€‚
è¿™ä¸æ˜¯ç©å…·ä»£ç ï¼Œè€Œæ˜¯ä¸€ä¸ªæ•™å­¦æ°ä½œï¼šå®ƒå‰¥ç¦»äº†æ‰€æœ‰å·¥ç¨‹å¤æ‚æ€§ï¼Œè®©ä½ çœ‹åˆ° GPT çš„ç®—æ³•æœ¬è´¨ã€‚">

  
</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >Muzig</a
    >
  </div>
  <div class="header-subtitle">Muzig çš„æŠ€æœ¯åšå®¢ï¼Œåˆ†äº« Go è¯­è¨€ã€AI æŠ€æœ¯ã€ç¼–ç¨‹è¯­è¨€è®¾è®¡ã€OpenClawã€Moltbotã€Clawdbot ç­‰æŠ€æœ¯æ–‡ç« </div>
</header>
<div class="row end-md header-items">
  <div class="header-item-left">
    <button id="theme-toggle" onclick="toggleTheme()" class="theme-toggle">
      ğŸŒ™
    </button>
  </div>

  
  <div class="header-item">
    <a href="https://github.com/muzig" target="_blank">About Me</a>
  </div>
  
</div>
<div class="row">
   
</div>
<div class="header-line"></div>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            <br \>
          </div>
          <div class="col-xs-12">
            
            <div class="post-tags">
              <a href="/tags/llm/">
                LLM
              </a>
            </div>
            
            <div class="post-tags">
              <a href="/tags/gpt/">
                GPT
              </a>
            </div>
            
            <div class="post-tags">
              <a href="/tags/transformer/">
                Transformer
              </a>
            </div>
            
            <div class="post-tags">
              <a href="/tags/python/">
                Python
              </a>
            </div>
            
            <div class="post-tags">
              <a href="/tags/education/">
                Education
              </a>
            </div>
            
            <div class="post-tags">
              <a href="/tags/karpathy/">
                Karpathy
              </a>
            </div>
            
          </div>
        </div>


        <header class="post-header">
          <h1 class="post-title">Karpathy microGPTï¼š200è¡Œçº¯Pythonå®ç°å®Œæ•´GPT</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime=" 2026-02-28 21:30:00 CST">
                28 Feb 2026
              </time>
              
            </div>
            <div class="col-xs-6">
              
            </div>
          </div>
          
        </header>



        <div class="post-content markdown-body">
          
          <blockquote>
<p><em>&ldquo;The most atomic way to train and run inference for a GPT in pure, dependency-free Python. This file is the complete algorithm. Everything else is just efficiency.&rdquo;</em> â€” Andrej Karpathy</p></blockquote>
<p>æœ€è¿‘ Andrej Karpathy å‘å¸ƒäº†ä¸€ä¸ªæç®€ GPT å®ç°ï¼š<strong>microgpt.py</strong> â€”â€” ä»… 200 è¡Œçº¯ Python ä»£ç ï¼Œæ— ä»»ä½•å¤–éƒ¨ä¾èµ–ï¼ˆåªç”¨æ ‡å‡†åº“ <code>os</code>, <code>math</code>, <code>random</code>ï¼‰ï¼Œå´åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒã€æ¨ç†æµç¨‹ã€‚</p>
<p>è¿™ä¸æ˜¯ç©å…·ä»£ç ï¼Œè€Œæ˜¯ä¸€ä¸ª<strong>æ•™å­¦æ°ä½œ</strong>ï¼šå®ƒå‰¥ç¦»äº†æ‰€æœ‰å·¥ç¨‹å¤æ‚æ€§ï¼Œè®©ä½ çœ‹åˆ° GPT çš„ç®—æ³•æœ¬è´¨ã€‚</p>
<hr>
<h2 id="ä¸ºä»€ä¹ˆæ˜¯è¿™-200-è¡Œ">ä¸ºä»€ä¹ˆæ˜¯è¿™ 200 è¡Œï¼Ÿ</h2>
<p>Karpathy åœ¨æ³¨é‡Šä¸­å†™é“ï¼š</p>
<blockquote>
<p><em>&ldquo;This file is the complete algorithm. Everything else is just efficiency.&rdquo;</em></p></blockquote>
<p>ç°ä»£ LLM æ¡†æ¶ï¼ˆPyTorch, Transformers, etc.ï¼‰å°è£…äº†å¤ªå¤šç»†èŠ‚ã€‚å½“ä½ è¯» nanoGPT æ—¶ï¼Œä»ç„¶éœ€è¦ç†è§£ï¼š</p>
<ul>
<li>PyTorch çš„ autograd æœºåˆ¶</li>
<li>CUDA kernel è°ƒç”¨</li>
<li>åˆ†å¸ƒå¼è®­ç»ƒé€»è¾‘</li>
</ul>
<p>è€Œ microgpt.py æŠŠä¸€åˆ‡éƒ½<strong>æ˜¾å¼åŒ–</strong>äº† â€”â€” æ¯ä¸ªæ•°å­¦è¿ç®—ã€æ¯ä¸ªæ¢¯åº¦è®¡ç®—éƒ½æ¸…æ™°å¯è§ã€‚</p>
<hr>
<h2 id="æ¶æ„å…¨æ™¯">æ¶æ„å…¨æ™¯</h2>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
</span></span><span style="display:flex;"><span>â”‚                        microGPT.py                          â”‚
</span></span><span style="display:flex;"><span>â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
</span></span><span style="display:flex;"><span>â”‚  1. Data Pipeline                                           â”‚
</span></span><span style="display:flex;"><span>â”‚     â””â”€â”€ ä¸‹è½½äººåæ•°æ®é›† â†’ å­—ç¬¦çº§Tokenizer â†’ BOSæ ‡è®°           â”‚
</span></span><span style="display:flex;"><span>â”‚                                                             â”‚
</span></span><span style="display:flex;"><span>â”‚  2. Autograd Engine (Valueç±»)                               â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ __add__, __mul__, __pow__                          â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ exp, log, relu                                     â”‚
</span></span><span style="display:flex;"><span>â”‚     â””â”€â”€ backward() â† æ‹“æ‰‘æ’åº+é“¾å¼æ³•åˆ™                      â”‚
</span></span><span style="display:flex;"><span>â”‚                                                             â”‚
</span></span><span style="display:flex;"><span>â”‚  3. Model Architecture                                      â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ Embeddings (wte, wpe)                              â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ Transformer Layer Ã— n_layer                        â”‚
</span></span><span style="display:flex;"><span>â”‚     â”‚   â”œâ”€â”€ RMSNorm                                        â”‚
</span></span><span style="display:flex;"><span>â”‚     â”‚   â”œâ”€â”€ Multi-Head Attention (Q, K, V, O)             â”‚
</span></span><span style="display:flex;"><span>â”‚     â”‚   â””â”€â”€ MLP (fc1 â†’ ReLU â†’ fc2)                        â”‚
</span></span><span style="display:flex;"><span>â”‚     â””â”€â”€ LM Head                                            â”‚
</span></span><span style="display:flex;"><span>â”‚                                                             â”‚
</span></span><span style="display:flex;"><span>â”‚  4. Training Loop                                           â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ Forward: build computation graph                   â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ Loss: cross-entropy                                â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ Backward: grad propagation                         â”‚
</span></span><span style="display:flex;"><span>â”‚     â””â”€â”€ Adam optimizer with LR decay                       â”‚
</span></span><span style="display:flex;"><span>â”‚                                                             â”‚
</span></span><span style="display:flex;"><span>â”‚  5. Inference                                               â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ KV-cache (keys, values accumulation)               â”‚
</span></span><span style="display:flex;"><span>â”‚     â”œâ”€â”€ Temperature sampling                               â”‚
</span></span><span style="display:flex;"><span>â”‚     â””â”€â”€ Token-by-token generation                          â”‚
</span></span><span style="display:flex;"><span>â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</span></span></code></pre></div><hr>
<h2 id="æ ¸å¿ƒå®ç°æ‹†è§£">æ ¸å¿ƒå®ç°æ‹†è§£</h2>
<h3 id="1-æ‰‹å†™è‡ªåŠ¨å¾®åˆ†value-ç±»">1. æ‰‹å†™è‡ªåŠ¨å¾®åˆ†ï¼šValue ç±»</h3>
<p>microgpt.py ä¸ä¾èµ– PyTorch çš„ autogradï¼Œè€Œæ˜¯è‡ªå·±å®ç°äº†ä¸€ä¸ª<strong>æ ‡é‡çº§</strong>è‡ªåŠ¨å¾®åˆ†å¼•æ“ï¼š</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold">class</span> <span style="font-weight:bold">Value</span>:
</span></span><span style="display:flex;"><span>    __slots__ = (<span style="font-style:italic">&#39;data&#39;</span>, <span style="font-style:italic">&#39;grad&#39;</span>, <span style="font-style:italic">&#39;_children&#39;</span>, <span style="font-style:italic">&#39;_local_grads&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __init__(self, data, children=(), local_grads=()):
</span></span><span style="display:flex;"><span>        self.data = data          <span style="font-style:italic"># å‰å‘è®¡ç®—å€¼</span>
</span></span><span style="display:flex;"><span>        self.grad = 0             <span style="font-style:italic"># æ¢¯åº¦ï¼ˆdL/dselfï¼‰</span>
</span></span><span style="display:flex;"><span>        self._children = children <span style="font-style:italic"># è®¡ç®—å›¾å­èŠ‚ç‚¹</span>
</span></span><span style="display:flex;"><span>        self._local_grads = local_grads  <span style="font-style:italic"># å±€éƒ¨æ¢¯åº¦</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __add__(self, other):
</span></span><span style="display:flex;"><span>        other = other <span style="font-weight:bold">if</span> isinstance(other, Value) <span style="font-weight:bold">else</span> Value(other)
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">return</span> Value(self.data + other.data, 
</span></span><span style="display:flex;"><span>                    (self, other), (1, 1))  <span style="font-style:italic"># âˆ‚(a+b)/âˆ‚a = 1</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __mul__(self, other):
</span></span><span style="display:flex;"><span>        other = other <span style="font-weight:bold">if</span> isinstance(other, Value) <span style="font-weight:bold">else</span> Value(other)
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">return</span> Value(self.data * other.data, 
</span></span><span style="display:flex;"><span>                    (self, other), (other.data, self.data))
</span></span></code></pre></div><p><strong>å…³é”®ç‚¹</strong>ï¼š</p>
<ul>
<li><code>__slots__</code> ä¼˜åŒ–å†…å­˜ä½¿ç”¨</li>
<li>æ¯ä¸ªæ“ä½œè®°å½•<strong>å­èŠ‚ç‚¹</strong>å’Œ<strong>å±€éƒ¨æ¢¯åº¦</strong></li>
<li>æ”¯æŒ <code>+</code>, <code>*</code>, <code>**</code>, <code>exp</code>, <code>log</code>, <code>relu</code> ç­‰è¿ç®—</li>
</ul>
<h3 id="2-åå‘ä¼ æ’­æ‹“æ‰‘æ’åº">2. åå‘ä¼ æ’­ï¼šæ‹“æ‰‘æ’åº</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold">def</span> backward(self):
</span></span><span style="display:flex;"><span>    <span style="font-style:italic"># æ‹“æ‰‘æ’åºæ„å»ºåå‘å›¾</span>
</span></span><span style="display:flex;"><span>    topo = []
</span></span><span style="display:flex;"><span>    visited = set()
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> build_topo(v):
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">if</span> v <span style="font-weight:bold">not</span> <span style="font-weight:bold">in</span> visited:
</span></span><span style="display:flex;"><span>            visited.add(v)
</span></span><span style="display:flex;"><span>            <span style="font-weight:bold">for</span> child <span style="font-weight:bold">in</span> v._children:
</span></span><span style="display:flex;"><span>                build_topo(child)
</span></span><span style="display:flex;"><span>            topo.append(v)
</span></span><span style="display:flex;"><span>    build_topo(self)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    self.grad = 1  <span style="font-style:italic"># dL/dL = 1</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">for</span> v <span style="font-weight:bold">in</span> reversed(topo):
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">for</span> child, local_grad <span style="font-weight:bold">in</span> zip(v._children, v._local_grads):
</span></span><span style="display:flex;"><span>            child.grad += local_grad * v.grad  <span style="font-style:italic"># é“¾å¼æ³•åˆ™</span>
</span></span></code></pre></div><p>è¿™ä¸ªå®ç°æ¸…æ™°å±•ç¤ºäº†<strong>åå‘ä¼ æ’­çš„æœ¬è´¨</strong>ï¼š</p>
<ol>
<li>æ‹“æ‰‘æ’åºç¡®å®šè®¡ç®—é¡ºåº</li>
<li>ä» loss èŠ‚ç‚¹å¼€å§‹ï¼Œæ¢¯åº¦=1</li>
<li>æŒ‰é€†åºéå†ï¼Œå°†æ¢¯åº¦é€šè¿‡é“¾å¼æ³•åˆ™ä¼ é€’</li>
</ol>
<h3 id="3-transformer-æ ¸å¿ƒ">3. Transformer æ ¸å¿ƒ</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold">def</span> gpt(token_id, pos_id, keys, values):
</span></span><span style="display:flex;"><span>    <span style="font-style:italic"># Embedding</span>
</span></span><span style="display:flex;"><span>    tok_emb = state_dict[<span style="font-style:italic">&#39;wte&#39;</span>][token_id]
</span></span><span style="display:flex;"><span>    pos_emb = state_dict[<span style="font-style:italic">&#39;wpe&#39;</span>][pos_id]
</span></span><span style="display:flex;"><span>    x = [t + p <span style="font-weight:bold">for</span> t, p <span style="font-weight:bold">in</span> zip(tok_emb, pos_emb)]
</span></span><span style="display:flex;"><span>    x = rmsnorm(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">for</span> li <span style="font-weight:bold">in</span> range(n_layer):
</span></span><span style="display:flex;"><span>        x_residual = x
</span></span><span style="display:flex;"><span>        x = rmsnorm(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="font-style:italic"># Multi-Head Attention</span>
</span></span><span style="display:flex;"><span>        q = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wq&#39;</span>])
</span></span><span style="display:flex;"><span>        k = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wk&#39;</span>])
</span></span><span style="display:flex;"><span>        v = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wv&#39;</span>])
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        keys[li].append(k)      <span style="font-style:italic"># KV-cache</span>
</span></span><span style="display:flex;"><span>        values[li].append(v)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="font-style:italic"># å¤šå¤´å¹¶è¡Œ</span>
</span></span><span style="display:flex;"><span>        x_attn = []
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">for</span> h <span style="font-weight:bold">in</span> range(n_head):
</span></span><span style="display:flex;"><span>            q_h = q[h * head_dim:(h+1) * head_dim]
</span></span><span style="display:flex;"><span>            k_h = [ki[h * head_dim:(h+1) * head_dim] <span style="font-weight:bold">for</span> ki <span style="font-weight:bold">in</span> keys[li]]
</span></span><span style="display:flex;"><span>            v_h = [vi[h * head_dim:(h+1) * head_dim] <span style="font-weight:bold">for</span> vi <span style="font-weight:bold">in</span> values[li]]
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="font-style:italic"># Attention: Q @ K^T / sqrt(d)</span>
</span></span><span style="display:flex;"><span>            attn_logits = [sum(q_h[j] * k_h[t][j] <span style="font-weight:bold">for</span> j <span style="font-weight:bold">in</span> range(head_dim)) 
</span></span><span style="display:flex;"><span>                          / head_dim**0.5 <span style="font-weight:bold">for</span> t <span style="font-weight:bold">in</span> range(len(k_h))]
</span></span><span style="display:flex;"><span>            attn_weights = softmax(attn_logits)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="font-style:italic"># Weighted sum</span>
</span></span><span style="display:flex;"><span>            head_out = [sum(attn_weights[t] * v_h[t][j] 
</span></span><span style="display:flex;"><span>                           <span style="font-weight:bold">for</span> t <span style="font-weight:bold">in</span> range(len(v_h))) <span style="font-weight:bold">for</span> j <span style="font-weight:bold">in</span> range(head_dim)]
</span></span><span style="display:flex;"><span>            x_attn.extend(head_out)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        x = linear(x_attn, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wo&#39;</span>])
</span></span><span style="display:flex;"><span>        x = [a + b <span style="font-weight:bold">for</span> a, b <span style="font-weight:bold">in</span> zip(x, x_residual)]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="font-style:italic"># MLP</span>
</span></span><span style="display:flex;"><span>        x_residual = x
</span></span><span style="display:flex;"><span>        x = rmsnorm(x)
</span></span><span style="display:flex;"><span>        x = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.mlp_fc1&#39;</span>])
</span></span><span style="display:flex;"><span>        x = [xi.relu() <span style="font-weight:bold">for</span> xi <span style="font-weight:bold">in</span> x]
</span></span><span style="display:flex;"><span>        x = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.mlp_fc2&#39;</span>])
</span></span><span style="display:flex;"><span>        x = [a + b <span style="font-weight:bold">for</span> a, b <span style="font-weight:bold">in</span> zip(x, x_residual)]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> linear(x, state_dict[<span style="font-style:italic">&#39;lm_head&#39;</span>])
</span></span></code></pre></div><p><strong>å€¼å¾—æ³¨æ„çš„ç»†èŠ‚</strong>ï¼š</p>
<ul>
<li>ä½¿ç”¨ <strong>RMSNorm</strong>ï¼ˆLLaMA é£æ ¼ï¼‰æ›¿ä»£ LayerNorm</li>
<li>æ˜¾å¼çš„ <strong>KV-cache</strong> æœºåˆ¶</li>
<li><strong>å•tokenå‰å‘</strong>ï¼šæ¯æ¬¡å¤„ç†ä¸€ä¸ª tokenï¼Œè€Œéæ•´ä¸ªåºåˆ—</li>
</ul>
<h3 id="4-rmsnormæç®€å½’ä¸€åŒ–">4. RMSNormï¼šæç®€å½’ä¸€åŒ–</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold">def</span> rmsnorm(x):
</span></span><span style="display:flex;"><span>    ms = sum(xi * xi <span style="font-weight:bold">for</span> xi <span style="font-weight:bold">in</span> x) / len(x)  <span style="font-style:italic"># å‡æ–¹</span>
</span></span><span style="display:flex;"><span>    scale = (ms + 1e-5) ** -0.5             <span style="font-style:italic"># 1/âˆš(ms+Îµ)</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> [xi * scale <span style="font-weight:bold">for</span> xi <span style="font-weight:bold">in</span> x]
</span></span></code></pre></div><p>æ¯” LayerNorm æ›´ç®€æ´ï¼Œçœå»äº†å‡å‡å€¼æ­¥éª¤ï¼Œæ•ˆæœç›¸è¿‘ã€‚</p>
<hr>
<h2 id="ç¤¾åŒºæ¢ç´¢æ•ˆç‡é˜¶æ¢¯">ç¤¾åŒºæ¢ç´¢ï¼šæ•ˆç‡é˜¶æ¢¯</h2>
<p>è¯„è®ºåŒºæœ‰äººåšäº†ä¸åŒå®ç°çš„æ€§èƒ½å¯¹æ¯”ï¼š</p>
<table>
  <thead>
      <tr>
          <th>å®ç°</th>
          <th>ç›¸å¯¹é€Ÿåº¦</th>
          <th>å…³é”®ä¼˜åŒ–</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>åŸç‰ˆ (Python scalar)</strong></td>
          <td>1Ã—</td>
          <td>æ‰‹å†™æ ‡é‡autograd</td>
      </tr>
      <tr>
          <td><strong>NumPy ç‰ˆ</strong></td>
          <td>~250Ã—</td>
          <td>çŸ©é˜µè¿ç®— + BLAS</td>
      </tr>
      <tr>
          <td><strong>PyTorch CPU</strong></td>
          <td>~200Ã—</td>
          <td>æ¡†æ¶ä¼˜åŒ–</td>
      </tr>
      <tr>
          <td><strong>PyTorch GPU (å°æ¨¡å‹)</strong></td>
          <td>æ›´æ…¢</td>
          <td>Kernelå¯åŠ¨å¼€é”€ &gt; è®¡ç®—æ”¶ç›Š</td>
      </tr>
  </tbody>
</table>
<blockquote>
<p>åŸæ–‡ï¼š<em>&ldquo;microGPT is compute-light and memory-light. For small models, CPU vectorization (BLAS) is often enough. GPU and distributed scaling only become clearly advantageous once arithmetic intensity increases via larger models or larger batch sizes.&rdquo;</em></p></blockquote>
<p><strong>æ ¸å¿ƒæ´å¯Ÿ</strong>ï¼šå°æ¨¡å‹ç“¶é¢ˆåœ¨ã€Œè®¡ç®—å›¾å¼€é”€ã€ï¼Œè€Œéè¯­è¨€/ç¡¬ä»¶ã€‚NumPy ç‰ˆæœ¬é€šè¿‡<strong>æ¶ˆé™¤æ ‡é‡autograd</strong>å’Œ<strong>è§£é‡Šå™¨å¼€é”€</strong>ï¼Œè·å¾—äº† 250 å€åŠ é€Ÿã€‚</p>
<hr>
<h2 id="ä¸ºä»€ä¹ˆå€¼å¾—ç²¾è¯»">ä¸ºä»€ä¹ˆå€¼å¾—ç²¾è¯»ï¼Ÿ</h2>
<ol>
<li><strong>æ•™è‚²ä»·å€¼</strong>ï¼šæ²¡æœ‰ä»»ä½•é»‘ç›’ï¼Œæ¯ä¸ªæ•°å­¦è¿ç®—éƒ½æ˜¾å¼å¯è§</li>
<li><strong>å·¥ç¨‹æ™ºæ…§</strong>ï¼šç”¨æœ€å°ä»£ç å±•ç¤º GPT çš„å®Œæ•´ pipeline</li>
<li><strong>æ€§èƒ½å¯ç¤º</strong>ï¼šè¯†åˆ«çœŸæ­£çš„ç“¶é¢ˆï¼Œé¿å…è¿‡æ—©ä¼˜åŒ–</li>
</ol>
<p>å¦‚æœä½ åˆšæ¥è§¦ Transformerï¼Œè¯»å®Œè¿™ 200 è¡Œï¼Œä½ ä¼šå¯¹ä»¥ä¸‹æ¦‚å¿µæœ‰<strong>ç›´è§‚ç†è§£</strong>ï¼š</p>
<ul>
<li>ä»€ä¹ˆæ˜¯è®¡ç®—å›¾ï¼Ÿåå‘ä¼ æ’­å¦‚ä½•å·¥ä½œï¼Ÿ</li>
<li>KV-cache ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ</li>
<li>å¤šå¤´æ³¨æ„åŠ›å¦‚ä½•å¹¶è¡Œè®¡ç®—ï¼Ÿ</li>
<li>Adam ä¼˜åŒ–å™¨çš„åå·®ä¿®æ­£æ˜¯ä»€ä¹ˆï¼Ÿ</li>
</ul>
<hr>
<h2 id="å®Œæ•´ä»£ç ">å®Œæ•´ä»£ç </h2>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-style:italic">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="font-style:italic">The most atomic way to train and run inference for a GPT in pure, dependency-free Python.
</span></span></span><span style="display:flex;"><span><span style="font-style:italic">This file is the complete algorithm.
</span></span></span><span style="display:flex;"><span><span style="font-style:italic">Everything else is just efficiency.
</span></span></span><span style="display:flex;"><span><span style="font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="font-style:italic">@karpathy
</span></span></span><span style="display:flex;"><span><span style="font-style:italic">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">import</span> <span style="font-weight:bold">os</span> <span style="font-style:italic"># os.path.exists</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">import</span> <span style="font-weight:bold">math</span> <span style="font-style:italic"># math.log, math.exp</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">import</span> <span style="font-weight:bold">random</span> <span style="font-style:italic"># random.seed, random.choices, random.gauss, random.shuffle</span>
</span></span><span style="display:flex;"><span>random.seed(42) <span style="font-style:italic"># Let there be order among chaos</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Let there be a Dataset `docs`: list[str] of documents (e.g. a list of names)</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">if</span> <span style="font-weight:bold">not</span> os.path.exists(<span style="font-style:italic">&#39;input.txt&#39;</span>):
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">import</span> <span style="font-weight:bold">urllib.request</span>
</span></span><span style="display:flex;"><span>    names_url = <span style="font-style:italic">&#39;https://raw.githubusercontent.com/karpathy/makemore/988aa59/names.txt&#39;</span>
</span></span><span style="display:flex;"><span>    urllib.request.urlretrieve(names_url, <span style="font-style:italic">&#39;input.txt&#39;</span>)
</span></span><span style="display:flex;"><span>docs = [line.strip() <span style="font-weight:bold">for</span> line <span style="font-weight:bold">in</span> open(<span style="font-style:italic">&#39;input.txt&#39;</span>) <span style="font-weight:bold">if</span> line.strip()]
</span></span><span style="display:flex;"><span>random.shuffle(docs)
</span></span><span style="display:flex;"><span>print(<span style="font-style:italic">f</span><span style="font-style:italic">&#34;num docs: </span><span style="font-weight:bold;font-style:italic">{</span>len(docs)<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Let there be a Tokenizer to translate strings to sequences of integers (&#34;tokens&#34;) and back</span>
</span></span><span style="display:flex;"><span>uchars = sorted(set(<span style="font-style:italic">&#39;&#39;</span>.join(docs))) <span style="font-style:italic"># unique characters in the dataset become token ids 0..n-1</span>
</span></span><span style="display:flex;"><span>BOS = len(uchars) <span style="font-style:italic"># token id for a special Beginning of Sequence (BOS) token</span>
</span></span><span style="display:flex;"><span>vocab_size = len(uchars) + 1 <span style="font-style:italic"># total number of unique tokens, +1 is for BOS</span>
</span></span><span style="display:flex;"><span>print(<span style="font-style:italic">f</span><span style="font-style:italic">&#34;vocab size: </span><span style="font-weight:bold;font-style:italic">{</span>vocab_size<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Let there be Autograd to recursively apply the chain rule through a computation graph</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">class</span> <span style="font-weight:bold">Value</span>:
</span></span><span style="display:flex;"><span>    __slots__ = (<span style="font-style:italic">&#39;data&#39;</span>, <span style="font-style:italic">&#39;grad&#39;</span>, <span style="font-style:italic">&#39;_children&#39;</span>, <span style="font-style:italic">&#39;_local_grads&#39;</span>) <span style="font-style:italic"># Python optimization for memory usage</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __init__(self, data, children=(), local_grads=()):
</span></span><span style="display:flex;"><span>        self.data = data <span style="font-style:italic"># scalar value of this node calculated during forward pass</span>
</span></span><span style="display:flex;"><span>        self.grad = 0 <span style="font-style:italic"># derivative of the loss w.r.t. this node, calculated in backward pass</span>
</span></span><span style="display:flex;"><span>        self._children = children <span style="font-style:italic"># children of this node in the computation graph</span>
</span></span><span style="display:flex;"><span>        self._local_grads = local_grads <span style="font-style:italic"># local derivative of this node w.r.t. its children</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __add__(self, other):
</span></span><span style="display:flex;"><span>        other = other <span style="font-weight:bold">if</span> isinstance(other, Value) <span style="font-weight:bold">else</span> Value(other)
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">return</span> Value(self.data + other.data, (self, other), (1, 1))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __mul__(self, other):
</span></span><span style="display:flex;"><span>        other = other <span style="font-weight:bold">if</span> isinstance(other, Value) <span style="font-weight:bold">else</span> Value(other)
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">return</span> Value(self.data * other.data, (self, other), (other.data, self.data))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __pow__(self, other): <span style="font-weight:bold">return</span> Value(self.data**other, (self,), (other * self.data**(other-1),))
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> log(self): <span style="font-weight:bold">return</span> Value(math.log(self.data), (self,), (1/self.data,))
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> exp(self): <span style="font-weight:bold">return</span> Value(math.exp(self.data), (self,), (math.exp(self.data),))
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> relu(self): <span style="font-weight:bold">return</span> Value(max(0, self.data), (self,), (float(self.data &gt; 0),))
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __neg__(self): <span style="font-weight:bold">return</span> self * -1
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __radd__(self, other): <span style="font-weight:bold">return</span> self + other
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __sub__(self, other): <span style="font-weight:bold">return</span> self + (-other)
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __rsub__(self, other): <span style="font-weight:bold">return</span> other + (-self)
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __rmul__(self, other): <span style="font-weight:bold">return</span> self * other
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __truediv__(self, other): <span style="font-weight:bold">return</span> self * other**-1
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> __rtruediv__(self, other): <span style="font-weight:bold">return</span> other * self**-1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">def</span> backward(self):
</span></span><span style="display:flex;"><span>        topo = []
</span></span><span style="display:flex;"><span>        visited = set()
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">def</span> build_topo(v):
</span></span><span style="display:flex;"><span>            <span style="font-weight:bold">if</span> v <span style="font-weight:bold">not</span> <span style="font-weight:bold">in</span> visited:
</span></span><span style="display:flex;"><span>                visited.add(v)
</span></span><span style="display:flex;"><span>                <span style="font-weight:bold">for</span> child <span style="font-weight:bold">in</span> v._children:
</span></span><span style="display:flex;"><span>                    build_topo(child)
</span></span><span style="display:flex;"><span>                topo.append(v)
</span></span><span style="display:flex;"><span>        build_topo(self)
</span></span><span style="display:flex;"><span>        self.grad = 1
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">for</span> v <span style="font-weight:bold">in</span> reversed(topo):
</span></span><span style="display:flex;"><span>            <span style="font-weight:bold">for</span> child, local_grad <span style="font-weight:bold">in</span> zip(v._children, v._local_grads):
</span></span><span style="display:flex;"><span>                child.grad += local_grad * v.grad
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Initialize the parameters, to store the knowledge of the model</span>
</span></span><span style="display:flex;"><span>n_layer = 1 <span style="font-style:italic"># depth of the transformer neural network (number of layers)</span>
</span></span><span style="display:flex;"><span>n_embd = 16 <span style="font-style:italic"># width of the network (embedding dimension)</span>
</span></span><span style="display:flex;"><span>block_size = 16 <span style="font-style:italic"># maximum context length of the attention window (note: the longest name is 15 characters)</span>
</span></span><span style="display:flex;"><span>n_head = 4 <span style="font-style:italic"># number of attention heads</span>
</span></span><span style="display:flex;"><span>head_dim = n_embd // n_head <span style="font-style:italic"># derived dimension of each head</span>
</span></span><span style="display:flex;"><span>matrix = <span style="font-weight:bold">lambda</span> nout, nin, std=0.08: [[Value(random.gauss(0, std)) <span style="font-weight:bold">for</span> _ <span style="font-weight:bold">in</span> range(nin)] <span style="font-weight:bold">for</span> _ <span style="font-weight:bold">in</span> range(nout)]
</span></span><span style="display:flex;"><span>state_dict = {<span style="font-style:italic">&#39;wte&#39;</span>: matrix(vocab_size, n_embd), <span style="font-style:italic">&#39;wpe&#39;</span>: matrix(block_size, n_embd), <span style="font-style:italic">&#39;lm_head&#39;</span>: matrix(vocab_size, n_embd)}
</span></span><span style="display:flex;"><span><span style="font-weight:bold">for</span> i <span style="font-weight:bold">in</span> range(n_layer):
</span></span><span style="display:flex;"><span>    state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>i<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wq&#39;</span>] = matrix(n_embd, n_embd)
</span></span><span style="display:flex;"><span>    state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>i<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wk&#39;</span>] = matrix(n_embd, n_embd)
</span></span><span style="display:flex;"><span>    state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>i<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wv&#39;</span>] = matrix(n_embd, n_embd)
</span></span><span style="display:flex;"><span>    state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>i<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wo&#39;</span>] = matrix(n_embd, n_embd)
</span></span><span style="display:flex;"><span>    state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>i<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.mlp_fc1&#39;</span>] = matrix(4 * n_embd, n_embd)
</span></span><span style="display:flex;"><span>    state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>i<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.mlp_fc2&#39;</span>] = matrix(n_embd, 4 * n_embd)
</span></span><span style="display:flex;"><span>params = [p <span style="font-weight:bold">for</span> mat <span style="font-weight:bold">in</span> state_dict.values() <span style="font-weight:bold">for</span> row <span style="font-weight:bold">in</span> mat <span style="font-weight:bold">for</span> p <span style="font-weight:bold">in</span> row] <span style="font-style:italic"># flatten params into a single list[Value]</span>
</span></span><span style="display:flex;"><span>print(<span style="font-style:italic">f</span><span style="font-style:italic">&#34;num params: </span><span style="font-weight:bold;font-style:italic">{</span>len(params)<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Define the model architecture: a function mapping tokens and parameters to logits over what comes next</span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Follow GPT-2, blessed among the GPTs, with minor differences: layernorm -&gt; rmsnorm, no biases, GeLU -&gt; ReLU</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">def</span> linear(x, w):
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> [sum(wi * xi <span style="font-weight:bold">for</span> wi, xi <span style="font-weight:bold">in</span> zip(wo, x)) <span style="font-weight:bold">for</span> wo <span style="font-weight:bold">in</span> w]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">def</span> softmax(logits):
</span></span><span style="display:flex;"><span>    max_val = max(val.data <span style="font-weight:bold">for</span> val <span style="font-weight:bold">in</span> logits)
</span></span><span style="display:flex;"><span>    exps = [(val - max_val).exp() <span style="font-weight:bold">for</span> val <span style="font-weight:bold">in</span> logits]
</span></span><span style="display:flex;"><span>    total = sum(exps)
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> [e / total <span style="font-weight:bold">for</span> e <span style="font-weight:bold">in</span> exps]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">def</span> rmsnorm(x):
</span></span><span style="display:flex;"><span>    ms = sum(xi * xi <span style="font-weight:bold">for</span> xi <span style="font-weight:bold">in</span> x) / len(x)
</span></span><span style="display:flex;"><span>    scale = (ms + 1e-5) ** -0.5
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> [xi * scale <span style="font-weight:bold">for</span> xi <span style="font-weight:bold">in</span> x]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">def</span> gpt(token_id, pos_id, keys, values):
</span></span><span style="display:flex;"><span>    tok_emb = state_dict[<span style="font-style:italic">&#39;wte&#39;</span>][token_id] <span style="font-style:italic"># token embedding</span>
</span></span><span style="display:flex;"><span>    pos_emb = state_dict[<span style="font-style:italic">&#39;wpe&#39;</span>][pos_id] <span style="font-style:italic"># position embedding</span>
</span></span><span style="display:flex;"><span>    x = [t + p <span style="font-weight:bold">for</span> t, p <span style="font-weight:bold">in</span> zip(tok_emb, pos_emb)] <span style="font-style:italic"># joint token and position embedding</span>
</span></span><span style="display:flex;"><span>    x = rmsnorm(x) <span style="font-style:italic"># note: not redundant due to backward pass via the residual connection</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">for</span> li <span style="font-weight:bold">in</span> range(n_layer):
</span></span><span style="display:flex;"><span>        <span style="font-style:italic"># 1) Multi-head Attention block</span>
</span></span><span style="display:flex;"><span>        x_residual = x
</span></span><span style="display:flex;"><span>        x = rmsnorm(x)
</span></span><span style="display:flex;"><span>        q = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wq&#39;</span>])
</span></span><span style="display:flex;"><span>        k = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wk&#39;</span>])
</span></span><span style="display:flex;"><span>        v = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wv&#39;</span>])
</span></span><span style="display:flex;"><span>        keys[li].append(k)
</span></span><span style="display:flex;"><span>        values[li].append(v)
</span></span><span style="display:flex;"><span>        x_attn = []
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">for</span> h <span style="font-weight:bold">in</span> range(n_head):
</span></span><span style="display:flex;"><span>            hs = h * head_dim
</span></span><span style="display:flex;"><span>            q_h = q[hs:hs+head_dim]
</span></span><span style="display:flex;"><span>            k_h = [ki[hs:hs+head_dim] <span style="font-weight:bold">for</span> ki <span style="font-weight:bold">in</span> keys[li]]
</span></span><span style="display:flex;"><span>            v_h = [vi[hs:hs+head_dim] <span style="font-weight:bold">for</span> vi <span style="font-weight:bold">in</span> values[li]]
</span></span><span style="display:flex;"><span>            attn_logits = [sum(q_h[j] * k_h[t][j] <span style="font-weight:bold">for</span> j <span style="font-weight:bold">in</span> range(head_dim)) / head_dim**0.5 <span style="font-weight:bold">for</span> t <span style="font-weight:bold">in</span> range(len(k_h))]
</span></span><span style="display:flex;"><span>            attn_weights = softmax(attn_logits)
</span></span><span style="display:flex;"><span>            head_out = [sum(attn_weights[t] * v_h[t][j] <span style="font-weight:bold">for</span> t <span style="font-weight:bold">in</span> range(len(v_h))) <span style="font-weight:bold">for</span> j <span style="font-weight:bold">in</span> range(head_dim)]
</span></span><span style="display:flex;"><span>            x_attn.extend(head_out)
</span></span><span style="display:flex;"><span>        x = linear(x_attn, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.attn_wo&#39;</span>])
</span></span><span style="display:flex;"><span>        x = [a + b <span style="font-weight:bold">for</span> a, b <span style="font-weight:bold">in</span> zip(x, x_residual)]
</span></span><span style="display:flex;"><span>        <span style="font-style:italic"># 2) MLP block</span>
</span></span><span style="display:flex;"><span>        x_residual = x
</span></span><span style="display:flex;"><span>        x = rmsnorm(x)
</span></span><span style="display:flex;"><span>        x = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.mlp_fc1&#39;</span>])
</span></span><span style="display:flex;"><span>        x = [xi.relu() <span style="font-weight:bold">for</span> xi <span style="font-weight:bold">in</span> x]
</span></span><span style="display:flex;"><span>        x = linear(x, state_dict[<span style="font-style:italic">f</span><span style="font-style:italic">&#39;layer</span><span style="font-weight:bold;font-style:italic">{</span>li<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">.mlp_fc2&#39;</span>])
</span></span><span style="display:flex;"><span>        x = [a + b <span style="font-weight:bold">for</span> a, b <span style="font-weight:bold">in</span> zip(x, x_residual)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    logits = linear(x, state_dict[<span style="font-style:italic">&#39;lm_head&#39;</span>])
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> logits
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Let there be Adam, the blessed optimizer and its buffers</span>
</span></span><span style="display:flex;"><span>learning_rate, beta1, beta2, eps_adam = 0.01, 0.85, 0.99, 1e-8
</span></span><span style="display:flex;"><span>m = [0.0] * len(params) <span style="font-style:italic"># first moment buffer</span>
</span></span><span style="display:flex;"><span>v = [0.0] * len(params) <span style="font-style:italic"># second moment buffer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Repeat in sequence</span>
</span></span><span style="display:flex;"><span>num_steps = 1000 <span style="font-style:italic"># number of training steps</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">for</span> step <span style="font-weight:bold">in</span> range(num_steps):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-style:italic"># Take single document, tokenize it, surround it with BOS special token on both sides</span>
</span></span><span style="display:flex;"><span>    doc = docs[step % len(docs)]
</span></span><span style="display:flex;"><span>    tokens = [BOS] + [uchars.index(ch) <span style="font-weight:bold">for</span> ch <span style="font-weight:bold">in</span> doc] + [BOS]
</span></span><span style="display:flex;"><span>    n = min(block_size, len(tokens) - 1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-style:italic"># Forward the token sequence through the model, building up the computation graph all the way to the loss</span>
</span></span><span style="display:flex;"><span>    keys, values = [[] <span style="font-weight:bold">for</span> _ <span style="font-weight:bold">in</span> range(n_layer)], [[] <span style="font-weight:bold">for</span> _ <span style="font-weight:bold">in</span> range(n_layer)]
</span></span><span style="display:flex;"><span>    losses = []
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">for</span> pos_id <span style="font-weight:bold">in</span> range(n):
</span></span><span style="display:flex;"><span>        token_id, target_id = tokens[pos_id], tokens[pos_id + 1]
</span></span><span style="display:flex;"><span>        logits = gpt(token_id, pos_id, keys, values)
</span></span><span style="display:flex;"><span>        probs = softmax(logits)
</span></span><span style="display:flex;"><span>        loss_t = -probs[target_id].log()
</span></span><span style="display:flex;"><span>        losses.append(loss_t)
</span></span><span style="display:flex;"><span>    loss = (1 / n) * sum(losses) <span style="font-style:italic"># final average loss over the document sequence. May yours be low.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-style:italic"># Backward the loss, calculating the gradients with respect to all model parameters</span>
</span></span><span style="display:flex;"><span>    loss.backward()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="font-style:italic"># Adam optimizer update: update the model parameters based on the corresponding gradients</span>
</span></span><span style="display:flex;"><span>    lr_t = learning_rate * (1 - step / num_steps) <span style="font-style:italic"># linear learning rate decay</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">for</span> i, p <span style="font-weight:bold">in</span> enumerate(params):
</span></span><span style="display:flex;"><span>        m[i] = beta1 * m[i] + (1 - beta1) * p.grad
</span></span><span style="display:flex;"><span>        v[i] = beta2 * v[i] + (1 - beta2) * p.grad ** 2
</span></span><span style="display:flex;"><span>        m_hat = m[i] / (1 - beta1 ** (step + 1))
</span></span><span style="display:flex;"><span>        v_hat = v[i] / (1 - beta2 ** (step + 1))
</span></span><span style="display:flex;"><span>        p.data -= lr_t * m_hat / (v_hat ** 0.5 + eps_adam)
</span></span><span style="display:flex;"><span>        p.grad = 0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="font-style:italic">f</span><span style="font-style:italic">&#34;step </span><span style="font-weight:bold;font-style:italic">{</span>step+1<span style="font-weight:bold;font-style:italic">:</span><span style="font-style:italic">4d</span><span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic"> / </span><span style="font-weight:bold;font-style:italic">{</span>num_steps<span style="font-weight:bold;font-style:italic">:</span><span style="font-style:italic">4d</span><span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic"> | loss </span><span style="font-weight:bold;font-style:italic">{</span>loss.data<span style="font-weight:bold;font-style:italic">:</span><span style="font-style:italic">.4f</span><span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">&#34;</span>, end=<span style="font-style:italic">&#39;</span><span style="font-weight:bold;font-style:italic">\r</span><span style="font-style:italic">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-style:italic"># Inference: may the model babble back to us</span>
</span></span><span style="display:flex;"><span>temperature = 0.5 <span style="font-style:italic"># in (0, 1], control the &#34;creativity&#34; of generated text, low to high</span>
</span></span><span style="display:flex;"><span>print(<span style="font-style:italic">&#34;</span><span style="font-weight:bold;font-style:italic">\n</span><span style="font-style:italic">--- inference (new, hallucinated names) ---&#34;</span>)
</span></span><span style="display:flex;"><span><span style="font-weight:bold">for</span> sample_idx <span style="font-weight:bold">in</span> range(20):
</span></span><span style="display:flex;"><span>    keys, values = [[] <span style="font-weight:bold">for</span> _ <span style="font-weight:bold">in</span> range(n_layer)], [[] <span style="font-weight:bold">for</span> _ <span style="font-weight:bold">in</span> range(n_layer)]
</span></span><span style="display:flex;"><span>    token_id = BOS
</span></span><span style="display:flex;"><span>    sample = []
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">for</span> pos_id <span style="font-weight:bold">in</span> range(block_size):
</span></span><span style="display:flex;"><span>        logits = gpt(token_id, pos_id, keys, values)
</span></span><span style="display:flex;"><span>        probs = softmax([l / temperature <span style="font-weight:bold">for</span> l <span style="font-weight:bold">in</span> logits])
</span></span><span style="display:flex;"><span>        token_id = random.choices(range(vocab_size), weights=[p.data <span style="font-weight:bold">for</span> p <span style="font-weight:bold">in</span> probs])[0]
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">if</span> token_id == BOS:
</span></span><span style="display:flex;"><span>            <span style="font-weight:bold">break</span>
</span></span><span style="display:flex;"><span>        sample.append(uchars[token_id])
</span></span><span style="display:flex;"><span>    print(<span style="font-style:italic">f</span><span style="font-style:italic">&#34;sample </span><span style="font-weight:bold;font-style:italic">{</span>sample_idx+1<span style="font-weight:bold;font-style:italic">:</span><span style="font-style:italic">2d</span><span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">: </span><span style="font-weight:bold;font-style:italic">{</span><span style="font-style:italic">&#39;&#39;</span>.join(sample)<span style="font-weight:bold;font-style:italic">}</span><span style="font-style:italic">&#34;</span>)
</span></span></code></pre></div><hr>
<h2 id="æ€»ç»“">æ€»ç»“</h2>
<p>microgpt.py æ˜¯ç†è§£ GPT çš„<strong>æœ€ä½³å…¥é—¨ææ–™</strong>ï¼š</p>
<ol>
<li><strong>é›¶ä¾èµ–</strong>ï¼šåªç”¨ Python æ ‡å‡†åº“ï¼Œä»»ä½•äººéƒ½èƒ½è¿è¡Œ</li>
<li><strong>å®Œæ•´æ€§</strong>ï¼šåŒ…å«è®­ç»ƒã€æ¨ç†ã€ä¼˜åŒ–å™¨ï¼Œæ˜¯çœŸæ­£çš„ end-to-end</li>
<li><strong>æ•™è‚²æ€§</strong>ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½æœ‰å¯¹åº”ä»£ç ï¼Œæ²¡æœ‰é»‘ç›’</li>
</ol>
<p>å¦‚æœä½ æƒ³æ·±å…¥ç†è§£ Transformerï¼Œä¸è¦ä» PyTorch æ–‡æ¡£å¼€å§‹ â€”â€” <strong>ä»è¿™ 200 è¡Œå¼€å§‹</strong>ã€‚</p>
<hr>
<h2 id="å‚è€ƒèµ„æ–™">å‚è€ƒèµ„æ–™</h2>
<ul>
<li><a href="https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95">microGPT Gist</a></li>
<li><a href="https://github.com/chanjoongx/microgpt-efficiency">microGPT-efficiency åŸºå‡†æµ‹è¯•</a></li>
<li><a href="https://github.com/karpathy/makemore">Karpathy&rsquo;s makemore</a></li>
<li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li>
</ul>
<hr>
<blockquote>
<p>ğŸ’¡ <strong>ä¸‹æœŸé¢„å‘Š</strong>ï¼šç”¨ NumPy åŠ é€Ÿ microGPT â€”â€” 250 å€æ€§èƒ½æå‡èƒŒåçš„åŸç†</p></blockquote>
<blockquote>
<p>ğŸ“¬ <strong>è®¢é˜…æ›´æ–°</strong>ï¼šå…³æ³¨å…¬ä¼—å·è·å–æœ€æ–°æŠ€æœ¯æ–‡ç« </p></blockquote>
        </div>

        
        <div class="row">
          <div class="col-xs-12">
            
          </div>
        </div>

        

<div class="related-content">
  <h3>Related Posts</h3>
  <ul>
    
    <li><a href="/2026/02/28/%E5%BD%93-andrej-karpathy-%E5%BC%80%E5%A7%8B%E7%BC%96%E7%A8%8B%E4%B8%80%E4%B8%AA%E7%A0%94%E7%A9%B6%E7%BB%84%E7%BB%87/">å½“ Andrej Karpathy å¼€å§‹&#34;ç¼–ç¨‹ä¸€ä¸ªç ”ç©¶ç»„ç»‡&#34;</a></li>
    
    <li><a href="/2026/02/03/llama.cpp-vs-vllm%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BA%91%E7%AB%AF%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%9E%B6%E6%9E%84%E6%8A%89%E6%8B%A9/">llama.cpp vs vLLMï¼šè¾¹ç¼˜éƒ¨ç½²ä¸äº‘ç«¯æœåŠ¡çš„æ¶æ„æŠ‰æ‹©</a></li>
    
  </ul>
</div>



        
        
        <div style="height: 50px;"></div>
        
        <div class="post-comments">
          <div id="disqus_thread"></div>
<script>
  window.addEventListener("load", () => {
    (function() {
      
      var d = document,
        s = d.createElement("script");
      s.src = "https://muzig.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  });
</script>
<noscript
  >Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript"
    >comments powered by Disqus.</a
  ></noscript
>

        </div>
        
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  
<script>
  
  document.addEventListener("DOMContentLoaded", function() {
    const disqus = document.getElementById('disqus_thread');
    if (!disqus) {
      return;
    }
    const observer = new MutationObserver(function(mutations) {
      mutations.forEach(function(mutation) {
        const iframes = disqus.getElementsByTagName('iframe');
        if (iframes.length > 1) {
          const commentsIframe = iframes[1];
          while (disqus.firstChild) {
            disqus.removeChild(disqus.firstChild);
          }
          disqus.appendChild(commentsIframe);
          observer.disconnect();
        }
      });
    });
    observer.observe(disqus, { childList: true, subtree: true });
  });
</script>

  

</body>

</html>